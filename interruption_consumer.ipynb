{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3674eb-5496-437e-846f-fcc7efc05065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import socket\n",
    "import pandas as pd\n",
    "from confluent_kafka import Consumer, KafkaError, KafkaException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fad260-36a1-45ee-a061-5fcaeb2254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksql import KSQLAPI\n",
    "import socket\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import mysql.connector as sql\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import os\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "            format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "            level=logging.INFO,\n",
    "            datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177ea77a-c848-4fc5-9a2b-3c486def587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf08115-ca48-412f-bac4-e7779092dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksql_data_helpers import return_det_counts_data, return_recent_data_ts,ts_str_to_unix, ts_unix_to_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554f709e-d5ad-49ed-909c-09574df240d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import return_det_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e29ca77-d7a2-4890-9f8c-9296d3b41afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_eoi = IscEoiStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc2b71-5bc5-486b-b889-e89d5be59f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc6196ad-6655-400e-9357-b5c9a90fe8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SIGNALID    WINDOWSTART      WINDOWEND  SUMFLAG  processed\n",
      "0     1010  1672703700000  1672705200000       25          1\n",
      "1     1015  1672703700000  1672705200000       25          1\n",
      "2     1873  1672703700000  1672705200000       25          1\n",
      "4     2565  1672703700000  1672705200000       25          1\n",
      "allrows\n",
      "[SIGNALID                1010\n",
      "WINDOWSTART    1672703700000\n",
      "WINDOWEND      1672705200000\n",
      "SUMFLAG                   25\n",
      "processed                  1\n",
      "Name: 0, dtype: object, SIGNALID                1015\n",
      "WINDOWSTART    1672703700000\n",
      "WINDOWEND      1672705200000\n",
      "SUMFLAG                   25\n",
      "processed                  1\n",
      "Name: 1, dtype: object, SIGNALID                1873\n",
      "WINDOWSTART    1672703700000\n",
      "WINDOWEND      1672705200000\n",
      "SUMFLAG                   25\n",
      "processed                  1\n",
      "Name: 2, dtype: object, SIGNALID                2565\n",
      "WINDOWSTART    1672703700000\n",
      "WINDOWEND      1672705200000\n",
      "SUMFLAG                   25\n",
      "processed                  1\n",
      "Name: 4, dtype: object]\n",
      "redu {'detector_id': '10103', 'end_time': '2023-01-02T19:19:59.999000', 'curr_volume': 3, 'curr_ma': 12.75, 'baseline': 12.0, 'reduction': 0.75}\n",
      "redu {'detector_id': '25654', 'end_time': '2023-01-02T19:19:59.999000', 'curr_volume': 23, 'curr_ma': 24.75, 'baseline': 30.35, 'reduction': 0.24217462932454697}\n",
      "redu {'detector_id': '10157', 'end_time': '2023-01-02T19:19:59.999000', 'curr_volume': 8, 'curr_ma': 8.75, 'baseline': 8.75, 'reduction': 0.08571428571428572}\n",
      "redu {'detector_id': '25655', 'end_time': '2023-01-02T19:19:59.999000', 'curr_volume': 21, 'curr_ma': 27.0, 'baseline': 31.25, 'reduction': 0.328}\n",
      "redu {'detector_id': '256512', 'end_time': '2023-01-02T19:19:59.999000', 'curr_volume': 27, 'curr_ma': 26.25, 'baseline': 28.4, 'reduction': 0.04929577464788728}\n"
     ]
    }
   ],
   "source": [
    "all_rows = isc_eoi.start_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3bb8fb3-83c3-482b-bfb2-f699181e41f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1010',\n",
       "  {10103: {'detector_id': '10103',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 3,\n",
       "    'curr_ma': 12.75,\n",
       "    'baseline': 12.0,\n",
       "    'reduction': 0.75},\n",
       "   10109: 'None',\n",
       "   101010: 'None'}),\n",
       " ('1015',\n",
       "  {10152: 'None',\n",
       "   10157: {'detector_id': '10157',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 8,\n",
       "    'curr_ma': 8.75,\n",
       "    'baseline': 8.75,\n",
       "    'reduction': 0.08571428571428572},\n",
       "   10158: 'None'}),\n",
       " ('1873', {}),\n",
       " ('2565',\n",
       "  {25654: {'detector_id': '25654',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 23,\n",
       "    'curr_ma': 24.75,\n",
       "    'baseline': 30.35,\n",
       "    'reduction': 0.24217462932454697},\n",
       "   25655: {'detector_id': '25655',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 21,\n",
       "    'curr_ma': 27.0,\n",
       "    'baseline': 31.25,\n",
       "    'reduction': 0.328},\n",
       "   256512: {'detector_id': '256512',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 27,\n",
       "    'curr_ma': 26.25,\n",
       "    'baseline': 28.4,\n",
       "    'reduction': 0.04929577464788728},\n",
       "   256513: 'None'})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d01a7-3d37-4f8e-b53e-b65aeb9b5531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "009139bb-5ee8-496e-b059-5d7c61a80cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redu {'detector_id': '25654', 'end_time': '2023-01-02T19:24:59.999000', 'curr_volume': 22, 'curr_ma': 23.5, 'baseline': 29.1, 'reduction': 0.2439862542955327}\n",
      "redu {'detector_id': '25655', 'end_time': '2023-01-02T19:24:59.999000', 'curr_volume': 16, 'curr_ma': 22.0, 'baseline': 28.7, 'reduction': 0.4425087108013937}\n",
      "redu {'detector_id': '256512', 'end_time': '2023-01-02T19:24:59.999000', 'curr_volume': 24, 'curr_ma': 27.0, 'baseline': 27.65, 'reduction': 0.13200723327305602}\n",
      "redu {'detector_id': '256513', 'end_time': '2023-01-02T19:24:59.999000', 'curr_volume': 29, 'curr_ma': 31.0, 'baseline': 34.55, 'reduction': 0.16063675832127344}\n"
     ]
    }
   ],
   "source": [
    "p = mp.Pool(isc_eoi.no_of_cores)\n",
    "results = p.map(isc_eoi.process_single_isc, all_rows)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52424012-0b9a-40f0-bf70-34c0bf6620fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e927a008-4278-4a56-a515-363641c836e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for isc_id, each_result in results:\n",
    "    if(isc_id not in isc_eoi.all_isc_store ): # isc is not yet in store,\n",
    "        isc_eoi.all_isc_store[isc_id]={} # dict for storing all dets\n",
    "        for det_id, det_value in each_result.items():\n",
    "            if(det_value != 'None'): # if reduction exist\n",
    "                isc_eoi.all_isc_store[isc_id][det_id]=[det_value]\n",
    "            else:\n",
    "                isc_eoi.all_isc_store[isc_id][det_id]=[]\n",
    "\n",
    "    else:\n",
    "        for det_id, det_value in each_result.items():\n",
    "            if(det_id not in isc_eoi.all_isc_store[isc_id]):\n",
    "                if(det_value != 'None'):\n",
    "                    isc_eoi.all_isc_store[isc_id][det_id]=[det_value]\n",
    "                else:\n",
    "                    isc_eoi.all_isc_store[isc_id][det_id] = []\n",
    "            else:\n",
    "                if(det_value != 'None'):\n",
    "                    isc_eoi.all_isc_store[isc_id][det_id].append(det_value)\n",
    "                else:\n",
    "                    isc_eoi.all_isc_store[isc_id][det_id] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "874dc99e-5762-4c8c-b5b9-6bcf3564d944",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1010': {10103: [],\n",
       "  10109: [{'detector_id': '10109',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 12,\n",
       "    'curr_ma': 12.5,\n",
       "    'baseline': 15.1,\n",
       "    'reduction': 0.2052980132450331}],\n",
       "  101010: []},\n",
       " '1015': {10152: [],\n",
       "  10157: [{'detector_id': '10157',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 8,\n",
       "    'curr_ma': 8.75,\n",
       "    'baseline': 8.75,\n",
       "    'reduction': 0.08571428571428572},\n",
       "   {'detector_id': '10157',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 6,\n",
       "    'curr_ma': 7.25,\n",
       "    'baseline': 8.333333333333334,\n",
       "    'reduction': 0.28}],\n",
       "  10158: [{'detector_id': '10158',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 7,\n",
       "    'curr_ma': 8.5,\n",
       "    'baseline': 8.5,\n",
       "    'reduction': 0.17647058823529413}]},\n",
       " '1873': {},\n",
       " '2565': {25654: [{'detector_id': '25654',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 23,\n",
       "    'curr_ma': 24.75,\n",
       "    'baseline': 30.35,\n",
       "    'reduction': 0.24217462932454697},\n",
       "   {'detector_id': '25654',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 22,\n",
       "    'curr_ma': 23.5,\n",
       "    'baseline': 29.1,\n",
       "    'reduction': 0.2439862542955327}],\n",
       "  25655: [{'detector_id': '25655',\n",
       "    'end_time': '2023-01-02T19:14:59.999000',\n",
       "    'curr_volume': 32,\n",
       "    'curr_ma': 30.0,\n",
       "    'baseline': 32.6,\n",
       "    'reduction': 0.018404907975460166},\n",
       "   {'detector_id': '25655',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 21,\n",
       "    'curr_ma': 27.0,\n",
       "    'baseline': 31.25,\n",
       "    'reduction': 0.328},\n",
       "   {'detector_id': '25655',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 16,\n",
       "    'curr_ma': 22.0,\n",
       "    'baseline': 28.7,\n",
       "    'reduction': 0.4425087108013937}],\n",
       "  256512: [{'detector_id': '256512',\n",
       "    'end_time': '2023-01-02T19:14:59.999000',\n",
       "    'curr_volume': 26,\n",
       "    'curr_ma': 26.75,\n",
       "    'baseline': 27.5,\n",
       "    'reduction': 0.05454545454545454},\n",
       "   {'detector_id': '256512',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 27,\n",
       "    'curr_ma': 26.25,\n",
       "    'baseline': 28.4,\n",
       "    'reduction': 0.04929577464788728},\n",
       "   {'detector_id': '256512',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 24,\n",
       "    'curr_ma': 27.0,\n",
       "    'baseline': 27.65,\n",
       "    'reduction': 0.13200723327305602}],\n",
       "  256513: [{'detector_id': '256513',\n",
       "    'end_time': '2023-01-02T19:24:59.999000',\n",
       "    'curr_volume': 29,\n",
       "    'curr_ma': 31.0,\n",
       "    'baseline': 34.55,\n",
       "    'reduction': 0.16063675832127344}]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isc_eoi.all_isc_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "955ee1b3-0fdc-4645-b92f-cadc094b3dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1010': {10103: [{'detector_id': '10103',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 3,\n",
       "    'curr_ma': 12.75,\n",
       "    'baseline': 12.0,\n",
       "    'reduction': 0.75}],\n",
       "  10109: [],\n",
       "  101010: []},\n",
       " '1015': {10152: [],\n",
       "  10157: [{'detector_id': '10157',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 8,\n",
       "    'curr_ma': 8.75,\n",
       "    'baseline': 8.75,\n",
       "    'reduction': 0.08571428571428572}],\n",
       "  10158: []},\n",
       " '1873': {},\n",
       " '2565': {25654: [{'detector_id': '25654',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 23,\n",
       "    'curr_ma': 24.75,\n",
       "    'baseline': 30.35,\n",
       "    'reduction': 0.24217462932454697}],\n",
       "  25655: [{'detector_id': '25655',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 21,\n",
       "    'curr_ma': 27.0,\n",
       "    'baseline': 31.25,\n",
       "    'reduction': 0.328}],\n",
       "  256512: [{'detector_id': '256512',\n",
       "    'end_time': '2023-01-02T19:19:59.999000',\n",
       "    'curr_volume': 27,\n",
       "    'curr_ma': 26.25,\n",
       "    'baseline': 28.4,\n",
       "    'reduction': 0.04929577464788728}],\n",
       "  256513: []}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isc_eoi.all_isc_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4282f85-faa2-4bd6-a327-1d07db551d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = isc_eoi.get_recent_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ada166-bede-4467-a0a9-4ebec91516b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIGNALID</th>\n",
       "      <th>WINDOWSTART</th>\n",
       "      <th>WINDOWEND</th>\n",
       "      <th>SUMFLAG</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>1672703100000</td>\n",
       "      <td>1672704600000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>1672703100000</td>\n",
       "      <td>1672704600000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1873</td>\n",
       "      <td>1672703100000</td>\n",
       "      <td>1672704600000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2565</td>\n",
       "      <td>1672703100000</td>\n",
       "      <td>1672704600000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SIGNALID    WINDOWSTART      WINDOWEND  SUMFLAG  processed\n",
       "0      1010  1672703100000  1672704600000       25          1\n",
       "3      1015  1672703100000  1672704600000       25          1\n",
       "6      1873  1672703100000  1672704600000       25          1\n",
       "12     2565  1672703100000  1672704600000       25          1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "006c6834-d1b1-4683-8c7d-d7019c33831b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1010': 1672705200000,\n",
       " '1015': 1672705200000,\n",
       " '1873': 1672705200000,\n",
       " '2565': 1672705200000}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isc_eoi.isc_last_processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb5de64-4641-423d-a76a-0aa9e3f4580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IscEoiStore():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.all_isc_store = {}\n",
    "        self.isc_last_processed = {}\n",
    "        self.map_file = pd.read_csv('MAPPINGS_DET_INFO_OCT_2022.csv')\n",
    "        self.reduction_threshold = 0.01\n",
    "        self.volume_threshold = 1\n",
    "        self.no_of_cores = 30\n",
    "        \n",
    "    def process_logic(self,signalid, window_end):\n",
    "        if(signalid not in self.isc_last_processed):\n",
    "            return 1\n",
    "        elif(window_end > self.isc_last_processed[signalid]):\n",
    "            return 1\n",
    "        return 0\n",
    "            \n",
    "        \n",
    "    def get_recent_status(self):\n",
    "        df = return_recent_data_ts(look_back_time = 15)\n",
    "        \n",
    "        df_filtered = df[df.SUMFLAG==25].copy()\n",
    "        df_filtered['processed'] = df_filtered.apply(lambda x : self.process_logic(x.SIGNALID, x.WINDOWEND), axis =1 )\n",
    "        df_filtered = df_filtered[df_filtered['processed']==1]\n",
    "        df_filtered = df_filtered.drop_duplicates(['SIGNALID'], keep='first')\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    def get_detector_ids(self, signalid):\n",
    "        all_dets = self.map_file[self.map_file.ATSPM_ID.isin([signalid])]\n",
    "        dets_of_interest = all_dets[(all_dets.phase.isin(['2','6'])) & (all_dets.distanceToStopbar >150) ]\n",
    "        # storing all the detector ID's. Detector ID is SignalID + Channel no.\n",
    "        detector_ids = []\n",
    "        for i, each_row in dets_of_interest.iterrows():\n",
    "            each_signal = each_row['ATSPM_ID']\n",
    "            channel = each_row['channel']\n",
    "            detector_ids.append(int(str(each_signal)+ str(channel)))\n",
    "        return detector_ids\n",
    "\n",
    "    def process_single_isc(self, row):\n",
    "        isc_result = {}\n",
    "        \n",
    "        all_dets = self.get_detector_ids(row.SIGNALID)\n",
    "        \n",
    "        for each_det in all_dets:\n",
    "            le = LabelEOI(each_det, row.WINDOWSTART, row.WINDOWEND)\n",
    "            reduction_flag, reduction_dict = le.get_EOI()\n",
    "            if(reduction_flag):\n",
    "                print(f\"redu {reduction_dict}\")\n",
    "                if((reduction_dict['reduction']>self.reduction_threshold) and(reduction_dict['curr_ma']>self.volume_threshold)):\n",
    "                    isc_result[each_det]= reduction_dict\n",
    "            else:\n",
    "                isc_result[each_det] = 'None'\n",
    "        return row.SIGNALID, isc_result\n",
    "                    \n",
    "    def start_processing(self):\n",
    "#         get current data\n",
    "        df_recent = self.get_recent_status()\n",
    "        print(df_recent)\n",
    "#     filter if next timestamp is available\n",
    "        all_rows = []\n",
    "    \n",
    "        for i, each_row in df_recent.iterrows():\n",
    "            if(each_row.SIGNALID not in self.isc_last_processed ):\n",
    "                all_rows.append(each_row)\n",
    "                self.isc_last_processed[each_row.SIGNALID] = each_row.WINDOWEND\n",
    "            else:\n",
    "                if(each_row.WINDOWEND>self.isc_last_processed[each_row.SIGNALID]):\n",
    "#                     new timestamp available\n",
    "                    all_rows.append(each_row)\n",
    "                    self.isc_last_processed[each_row.SIGNALID] = each_row.WINDOWEND\n",
    "#         return all_rows\n",
    "#     parallel process all rows\n",
    "        print(f\"allrows\")\n",
    "        print(all_rows)\n",
    "        p = mp.Pool(self.no_of_cores)\n",
    "        results = p.map(self.process_single_isc, all_rows)\n",
    "        p.close()\n",
    "        \n",
    "        for isc_id, each_result in results:\n",
    "            if(isc_id not in self.all_isc_store ): # isc is not yet in store,\n",
    "                self.all_isc_store[isc_id]={} # dict for storing all dets\n",
    "                for det_id, det_value in each_result.items():\n",
    "                    if(det_value != 'None'): # if reduction exist\n",
    "                        self.all_isc_store[isc_id][det_id]=[det_value]\n",
    "                    else:\n",
    "                        self.all_isc_store[isc_id][det_id]=[]\n",
    "                        \n",
    "            else:\n",
    "                for det_id, det_value in each_result.items():\n",
    "                    if(det_id not in self.all_isc_store[isc_id]):\n",
    "                        if(det_value != 'None'):\n",
    "                            self.all_isc_store[isc_id][det_id]=[det_value]\n",
    "                        else:\n",
    "                            self.all_isc_store[isc_id][det_id] = []\n",
    "                    else:\n",
    "                        if(det_value != 'None'):\n",
    "                            self.all_isc_store[isc_id][det_id].append(det_value)\n",
    "                        else:\n",
    "                            self.all_isc_store[isc_id][det_id] = []\n",
    "                            \n",
    "                \n",
    "            \n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a96bae94-3ca9-4d7a-ada5-d6b005c205ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEOI():\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, detector_id, start_time, end_time):\n",
    "        super().__init__()\n",
    "        self.no_of_cores = 30\n",
    "        self.aggregation_level = 300\n",
    "        self.min_prev_data = 2\n",
    "        self.window_size = 4\n",
    "        self.detector_id =str(detector_id)\n",
    "        self.start_time= start_time\n",
    "        self.end_time = end_time-1 \n",
    "\n",
    "\n",
    "        # ALL THRESHOLDS  AND CONSTANTS\n",
    "        self.DET_HISTORY_VOLUME_THRESHOLD = 10\n",
    "        self.time_start = '07:00'\n",
    "        self.time_end = '21:00'\n",
    "        self.prev_days_to_consider = [7,14,21]\n",
    "        self.current_weight = 2\n",
    "        self.history_weight = 1\n",
    "\n",
    "        \n",
    "    def compute_historic_baseline(self, row):\n",
    "\n",
    "        \"\"\"\n",
    "        Computes historic baseline traffic for a given time interval\n",
    "        Parameters\n",
    "        ----------\n",
    "        row : dataframe row\n",
    "            More info to be displayed (default is None)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        value: float\n",
    "            traffic volume baseline\n",
    "        \"\"\"\n",
    "        all_prev = ['MA_prev_7','MA_prev_14','MA_prev_21' ]\n",
    "        value = 0\n",
    "        count = self.current_weight\n",
    "        value += self.current_weight*row['MA_curr']\n",
    "        for prev in all_prev:\n",
    "            if(prev in row and row[prev]>self.DET_HISTORY_VOLUME_THRESHOLD):\n",
    "                value+=self.history_weight*row[prev]\n",
    "                count+=self.history_weight\n",
    "                \n",
    "        return value/count\n",
    "    \n",
    "    def get_EOI(self):\n",
    "        flag, hist_df = self.return_hist_df()\n",
    "        if(flag):\n",
    "            last_row = hist_df.iloc[-1]\n",
    "            curr_vol = last_row.Count\n",
    "            curr_ma = last_row.MA_curr\n",
    "            reduction =  (last_row.baseline- curr_vol)/(last_row.baseline)\n",
    "            reducton_dict = {'detector_id':self.detector_id, 'end_time':ts_unix_to_ts(self.end_time), 'curr_volume':curr_vol, 'curr_ma':curr_ma,'baseline':last_row.baseline, 'reduction':reduction}\n",
    "            if(reduction>0):\n",
    "                return True, reducton_dict\n",
    "            else:\n",
    "                return False, 0\n",
    "        return False, 0\n",
    "            \n",
    "    \n",
    "    \n",
    "    def return_hist_df(self):\n",
    "        # current data\n",
    "        count_df = return_det_counts_data(self.detector_id , self.start_time, self.end_time)\n",
    "#         count_df.rename(columns={'EventCode': 'Count_curr'}, inplace=True)\n",
    "\n",
    "        count_df.rename(columns={'COUNT': 'Count'}, inplace=True)\n",
    "        ll = f\"{self.aggregation_level}s\"\n",
    "        count_df= count_df.resample(ll).sum()\n",
    "        count_df['MA_curr'] = count_df.rolling(window=self.window_size ).mean()\n",
    "        count_df.fillna(method='bfill', inplace = True)\n",
    "        count_df['time'] = count_df.index.time\n",
    "        \n",
    "        \n",
    "        # history from previous weeks\n",
    "\n",
    "\n",
    "        prev_count ={}\n",
    "        all_prev = [7,14, 21]\n",
    "        for i in  all_prev:\n",
    "            start_time_prev =  (pd.to_datetime(ts_unix_to_ts(self.start_time)) - pd.Timedelta(days=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            end_time_prev =  (pd.to_datetime(ts_unix_to_ts(self.end_time)) - pd.Timedelta(days=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            # print(f\"time prev {time_prev}\")\n",
    "\n",
    "            count_df_prev = return_det_waveform(self.detector_id ,start_time_prev, end_time_prev)\n",
    "#             print(f\"count_df_prev shape {count_df_prev.shape}\")\n",
    "            if(count_df_prev.shape[0]<5):\n",
    "                pass\n",
    "            else:\n",
    "        #         count_df_prev.drop(columns = ['SignalID','EventParam'], inplace = True)\n",
    "        #         count_df_prev.rename(columns={'EventCode': 'Count'}, inplace=True)\n",
    "                ll = f\"{self.aggregation_level}s\"\n",
    "                count_df_prev= count_df_prev.resample(ll).sum()\n",
    "                count_df_prev[f'MA_prev_{i}'] = count_df_prev.rolling(window=self.window_size).mean()\n",
    "                count_df_prev[f'time'] =  count_df_prev.index.time\n",
    "                count_df_prev.fillna(method='bfill', inplace = True)\n",
    "                prev_count[i]  = count_df_prev  \n",
    "                \n",
    "                \n",
    "        all_merged_df =   count_df.copy() \n",
    "        all_merged_df['timestamp'] = all_merged_df.index\n",
    "        #         print(f\"Yash DEBUG   all_merged_df {all_merged_df.head(5)}\" )\n",
    "        \n",
    "#         print(f\"prev count {len(prev_count)}\")\n",
    "        if(len(prev_count) > self.min_prev_data):\n",
    "            for k,each_prev in   prev_count.items():\n",
    "                all_merged_df = pd.merge(all_merged_df,each_prev, on = 'time')\n",
    "                \n",
    "            all_merged_df['baseline'] = all_merged_df.apply(lambda x: self.compute_historic_baseline(x), axis = 1) \n",
    "            all_merged_df['DetectorID'] = self.detector_id\n",
    "            all_merged_df.set_index('timestamp', inplace = True)\n",
    "            \n",
    "            return True, all_merged_df\n",
    "        else:\n",
    "            return False, None\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4723f-77b4-4dc4-8863-857399680433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa4b25-3096-4b4e-ad83-abd555f87a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05f18b-02d6-4c9f-b2b9-c10806a7d2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b1131-d495-4ecd-89ab-622b8e2182c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5604e21-16c1-4531-b9e0-a52b63d19f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a0038-23a9-4f16-b43e-48c027f55df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d0a84-6b61-43f0-a1b9-0667f7764666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98154011-ac50-4e17-8fe9-8e8f5e6e2450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e3e99-82e1-4679-a1eb-0dbcb797cd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367d401-f496-43ab-b646-ef1789051ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a2e4f-adb0-4426-b599-0d6afbe106f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d9161-0e3e-487f-bfaa-c85f3c09c7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fb8ca0-a556-4730-8c0f-1151427cb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = KSQLAPI('http://localhost:8088')\n",
    "streamProperties = {\n",
    "    \"ksql.streams.auto.offset.reset\": \"earliest\", \n",
    "    \"ksql.query.pull.table.scan.enabled\": \"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c564a4-1ce6-4397-a98a-bdebb6e5b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05e717b-fb88-494c-bdda-87f093e1ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_columns(columns_str):\n",
    "    regex = r\"(?<!\\<)`(?P<name>[A-Z_]+)` (?P<type>[A-z]+)[\\<, \\\"](?!\\>)\"\n",
    "    result = []\n",
    "\n",
    "    matches = re.finditer(regex, columns_str)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        result.append({\"name\": match.group(\"name\"), \"type\": match.group(\"type\")})\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_row(row, column_names):\n",
    "    row = row.replace(\",\\n\", \"\").replace(\"]\\n\", \"\").rstrip(\"]\")\n",
    "    row_obj = json.loads(row)\n",
    "    if \"finalMessage\" in row_obj:\n",
    "        return None\n",
    "    column_values = row_obj[\"row\"][\"columns\"]\n",
    "    index = 0\n",
    "    result = {}\n",
    "    for column in column_values:\n",
    "        result[column_names[index][\"name\"]] = column\n",
    "        index += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_query_result(results, return_objects=None):\n",
    "    if return_objects is None:\n",
    "        yield from results\n",
    "\n",
    "    # parse rows into objects\n",
    "    try:\n",
    "        header = next(results)\n",
    "    except StopIteration:\n",
    "        return\n",
    "    columns = parse_columns(header)\n",
    "\n",
    "    for result in results:\n",
    "        row_obj = process_row(result, columns)\n",
    "        if row_obj is None:\n",
    "            return\n",
    "        yield row_obj\n",
    "        \n",
    "def return_query_df(ksql_string):\n",
    "    query = client.query(ksql_string, stream_properties=streamProperties)\n",
    "    tspm = list(process_query_result(query, return_objects=True))\n",
    "    return pd.DataFrame(tspm)\n",
    " \n",
    "\n",
    "def ts_unix_to_ts(time_unix):\n",
    "    dt = datetime.fromtimestamp(time_unix/1000)\n",
    "    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')    \n",
    "    \n",
    "def ts_str_to_unix(time_str):\n",
    "    dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return int(time.mktime(dt.timetuple()) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a680171-5f6d-4ba3-a621-3daf0ffe8899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1296e43-72d3-4260-a827-a6b02edd376a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01a2194-c4e4-4138-8cb4-b0b1296d3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO RETURN MOST RECENT BIT MASK FOR ALL INTERSECTIONS\n",
    "def return_recent_data_ts(look_back_time = 15):\n",
    "    '''\n",
    "    look_back_time: time in min \n",
    "    '''\n",
    "    current_time_ms= round(time.time()*1000)\n",
    "    look_time = current_time_ms - look_back_time*60*1000\n",
    "    TABLE_NAME = 'ATSPM_MASK_1500SEC' #THIS IS A TABLE\n",
    "    ksql_string = f'SELECT *  from {TABLE_NAME} where WINDOWEND >=' + f'{look_time}' \n",
    "    print(ksql_string)\n",
    "    df = return_query_df(ksql_string)\n",
    "    return df\n",
    "\n",
    "\n",
    "# FUNCTION TO RETURN COUNTS FOR A DETECTOR BETWEEN START AND END TIME. 5 sec aggregation\n",
    "def return_det_counts_data(detector_id, time_start, time_end):\n",
    "    '''\n",
    "    detector_id: detector_id string (signalID + channel value)\n",
    "    start_time: unix time in ms (INT)\n",
    "    end_time: unix time in ms(INT)\n",
    "    '''\n",
    "    TABLE_NAME = 'COUNTS_RAW_STREAM_V1_AGG_5SEC' #Detector ID to counts  #THIS IS A TABLE\n",
    "    ksql_string = f'SELECT * FROM {TABLE_NAME} where DETECTORID = ' +  \"'\" + detector_id + \"'\"   + f' AND WINDOWSTART>={time_start} AND WINDOWSTART < {time_end}'\n",
    "    print(ksql_string)\n",
    "    temp_df = return_query_df(ksql_string)\n",
    "    \n",
    "    temp_df.drop(columns = ['DETECTORID', 'WINDOWEND'], inplace = True)\n",
    "    new_row = pd.Series(data={'WINDOWSTART':time_start,'COUNT':0}, name=0)\n",
    "    temp_df = temp_df.append(new_row, ignore_index=False)\n",
    "    new_row = pd.Series(data={'WINDOWSTART':time_end,'COUNT':0}, name=0)\n",
    "    temp_df = temp_df.append(new_row, ignore_index=False)\n",
    "    temp_df['timestamp']  = pd.to_datetime(temp_df['WINDOWSTART'], unit = 'ms').dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    temp_df.set_index('timestamp', inplace = True)\n",
    "    temp_df.drop(columns = ['WINDOWSTART'], inplace = True)\n",
    "    temp_df.sort_index(inplace = True)\n",
    "\n",
    "    final_df = temp_df.resample('5s').sum()\n",
    "    \n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4a8b2e-c623-4b82-a0e1-b7b32eaa6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT *  from ATSPM_MASK_1500SEC where WINDOWEND >=1672283807888\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5416dbce-4fbe-435b-bd11-406d5dbc4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 22:32:00 INFO     Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-12-28 22:32:00 INFO     NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df.SUMFLAG==25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec2a95d-f84c-43ff-95f1-8a56b6199cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIGNALID</th>\n",
       "      <th>WINDOWSTART</th>\n",
       "      <th>WINDOWEND</th>\n",
       "      <th>SUMFLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>1672282500000</td>\n",
       "      <td>1672284000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1015</td>\n",
       "      <td>1672282500000</td>\n",
       "      <td>1672284000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1015</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1873</td>\n",
       "      <td>1672282500000</td>\n",
       "      <td>1672284000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1873</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2565</td>\n",
       "      <td>1672282500000</td>\n",
       "      <td>1672284000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2565</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SIGNALID    WINDOWSTART      WINDOWEND  SUMFLAG\n",
       "0      1010  1672282500000  1672284000000       25\n",
       "1      1010  1672282800000  1672284300000       25\n",
       "7      1015  1672282500000  1672284000000       25\n",
       "8      1015  1672282800000  1672284300000       25\n",
       "15     1873  1672282500000  1672284000000       25\n",
       "16     1873  1672282800000  1672284300000       25\n",
       "22     2565  1672282500000  1672284000000       25\n",
       "23     2565  1672282800000  1672284300000       25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcc0f7a-267d-485c-b071-b15a40817839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop_duplicates(['SIGNALID'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab6f4c33-bea9-4680-875a-ff4a475a7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIGNALID</th>\n",
       "      <th>WINDOWSTART</th>\n",
       "      <th>WINDOWEND</th>\n",
       "      <th>SUMFLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1015</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1873</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2565</td>\n",
       "      <td>1672282800000</td>\n",
       "      <td>1672284300000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SIGNALID    WINDOWSTART      WINDOWEND  SUMFLAG\n",
       "1      1010  1672282800000  1672284300000       25\n",
       "8      1015  1672282800000  1672284300000       25\n",
       "16     1873  1672282800000  1672284300000       25\n",
       "23     2565  1672282800000  1672284300000       25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45663fc6-f0e1-482d-a0b4-a0f104108f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_row = df_filtered.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be972ab2-9188-495c-9e5e-14674e889741",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dets = map_file[map_file.ATSPM_ID.isin([curr_row.SIGNALID])]\n",
    "dets_of_interest = all_dets[(all_dets.phase.isin(['2','6'])) & (all_dets.distanceToStopbar >150) ]\n",
    "\n",
    "# storing all the detector ID's. Detector ID is SignalID + Channel no.\n",
    "detector_ids = []\n",
    "for i, each_row in dets_of_interest.iterrows():\n",
    "    each_signal = each_row['ATSPM_ID']\n",
    "    channel = each_row['channel']\n",
    "    detector_ids.append(int(str(each_signal)+ str(channel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eec51ca-c122-4b16-a5fd-d80c3f3b33d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10103, 10109, 101010]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96f31a39-59e1-4915-a524-365c8ab5e133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIGNALID                1010\n",
       "WINDOWSTART    1672282800000\n",
       "WINDOWEND      1672284300000\n",
       "SUMFLAG                   25\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d5f9969-4dfc-40c6-bb2f-f985e59c2780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM COUNTS_RAW_STREAM_V1_AGG_5SEC where DETECTORID = '10109' AND WINDOWSTART>=1672282800000 AND WINDOWSTART < 1672284299999\n"
     ]
    }
   ],
   "source": [
    "# for one detector \n",
    "\n",
    "det_id = str(detector_ids[1])\n",
    "\n",
    "# current data\n",
    "count_df = return_det_counts_data(det_id, curr_row.WINDOWSTART, curr_row.WINDOWEND-1)\n",
    "count_df.rename(columns={'EventCode': 'Count_curr'}, inplace=True)\n",
    "\n",
    "count_df.rename(columns={'COUNT': 'Count_curr'}, inplace=True)\n",
    "ll = f\"300s\"\n",
    "count_df= count_df.resample(ll).sum()\n",
    "count_df['MA_curr'] = count_df.rolling(window=4 ).mean()\n",
    "count_df.fillna(method='bfill', inplace = True)\n",
    "count_df['time'] = count_df.index.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3df3fb93-8b78-49b9-8507-f49dd09e7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history from previous weeks\n",
    "\n",
    "\n",
    "start_time= ts_unix_to_ts(curr_row.WINDOWSTART)\n",
    "end_time = ts_unix_to_ts(curr_row.WINDOWEND-1)\n",
    "prev_count ={}\n",
    "all_prev = [7,14, 21]\n",
    "for i in  all_prev:\n",
    "    start_time_prev =  (pd.to_datetime(start_time) - pd.Timedelta(days=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time_prev =  (pd.to_datetime(end_time) - pd.Timedelta(days=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # print(f\"time prev {time_prev}\")\n",
    "\n",
    "    count_df_prev = return_det_waveform(det_id,start_time_prev, end_time_prev)\n",
    "    # print(f\"count_df_prev shape {count_df_prev.shape}\")\n",
    "    if(count_df_prev.shape[0]<5):\n",
    "        pass\n",
    "    else:\n",
    "#         count_df_prev.drop(columns = ['SignalID','EventParam'], inplace = True)\n",
    "#         count_df_prev.rename(columns={'EventCode': 'Count'}, inplace=True)\n",
    "        ll = f\"300s\"\n",
    "        count_df_prev= count_df_prev.resample(ll).sum()\n",
    "        count_df_prev[f'MA_prev_{i}'] = count_df_prev.rolling(window=4).mean()\n",
    "        count_df_prev[f'time'] =  count_df_prev.index.time\n",
    "        count_df_prev.fillna(method='bfill', inplace = True)\n",
    "        prev_count[i]  = count_df_prev  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c9206cf-891f-4de6-81b2-5feb6a7cf726",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df =   count_df.copy() \n",
    "all_merged_df['timestamp'] = all_merged_df.index\n",
    "#         print(f\"Yash DEBUG   all_merged_df {all_merged_df.head(5)}\" )\n",
    "if(len(prev_count) > 2):\n",
    "    for k,each_prev in   prev_count.items():\n",
    "#                 all_merged_df = pd.merge(all_merged_df,each_prev, on = 'time', right_index= True)\n",
    "        all_merged_df = pd.merge(all_merged_df,each_prev, on = 'time')\n",
    "#                 print(f\"Yash DEBUG   all_merged_df  last {all_merged_df.head(5)}\" )\n",
    "    all_merged_df['baseline'] = all_merged_df.apply(lambda x: compute_historic_baseline(x), axis = 1)\n",
    "    all_merged_df['DetectorID'] = det_id\n",
    "    all_merged_df.set_index('timestamp', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f90bc895-618e-4da9-88dc-888ec42b06d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_curr_x</th>\n",
       "      <th>MA_curr</th>\n",
       "      <th>time</th>\n",
       "      <th>Count_curr_y</th>\n",
       "      <th>MA_prev_7</th>\n",
       "      <th>Count_curr_x</th>\n",
       "      <th>MA_prev_14</th>\n",
       "      <th>Count_curr_y</th>\n",
       "      <th>MA_prev_21</th>\n",
       "      <th>baseline</th>\n",
       "      <th>DetectorID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28 22:00:00-05:00</th>\n",
       "      <td>14</td>\n",
       "      <td>10.5</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 22:05:00-05:00</th>\n",
       "      <td>15</td>\n",
       "      <td>10.5</td>\n",
       "      <td>22:05:00</td>\n",
       "      <td>10</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 22:10:00-05:00</th>\n",
       "      <td>6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>22:10:00</td>\n",
       "      <td>20</td>\n",
       "      <td>14.00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 22:15:00-05:00</th>\n",
       "      <td>7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>22:15:00</td>\n",
       "      <td>18</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 22:20:00-05:00</th>\n",
       "      <td>10</td>\n",
       "      <td>9.5</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>7</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.916667</td>\n",
       "      <td>10109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Count_curr_x  MA_curr      time  Count_curr_y  \\\n",
       "timestamp                                                                  \n",
       "2022-12-28 22:00:00-05:00            14     10.5  22:00:00             8   \n",
       "2022-12-28 22:05:00-05:00            15     10.5  22:05:00            10   \n",
       "2022-12-28 22:10:00-05:00             6     10.5  22:10:00            20   \n",
       "2022-12-28 22:15:00-05:00             7     10.5  22:15:00            18   \n",
       "2022-12-28 22:20:00-05:00            10      9.5  22:20:00             7   \n",
       "\n",
       "                           MA_prev_7  Count_curr_x  MA_prev_14  Count_curr_y  \\\n",
       "timestamp                                                                      \n",
       "2022-12-28 22:00:00-05:00      14.00             1        3.00             3   \n",
       "2022-12-28 22:05:00-05:00      14.00             3        3.00             8   \n",
       "2022-12-28 22:10:00-05:00      14.00             5        3.00             2   \n",
       "2022-12-28 22:15:00-05:00      14.00             3        3.00             5   \n",
       "2022-12-28 22:20:00-05:00      13.75             0        2.75             7   \n",
       "\n",
       "                           MA_prev_21   baseline DetectorID  \n",
       "timestamp                                                    \n",
       "2022-12-28 22:00:00-05:00         4.5  11.666667      10109  \n",
       "2022-12-28 22:05:00-05:00         4.5  11.666667      10109  \n",
       "2022-12-28 22:10:00-05:00         4.5  11.666667      10109  \n",
       "2022-12-28 22:15:00-05:00         4.5  11.666667      10109  \n",
       "2022-12-28 22:20:00-05:00         5.5  10.916667      10109  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30cfda-1d76-4aec-8d10-22c86a38c0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f9a06-a443-4698-b26d-35a30bb91c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f9b6ca-bed5-4435-9886-9c235a3c8215",
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_historic_baseline(row):\n",
    "\n",
    "        all_prev = ['MA_prev_7','MA_prev_14','MA_prev_21' ]\n",
    "        value = 0\n",
    "        count = 2\n",
    "        value += 2*row['MA_curr']\n",
    "        for prev in all_prev:\n",
    "            if(prev in row and row[prev]>10):\n",
    "                value+=1*row[prev]\n",
    "                count+=1\n",
    "                \n",
    "        return value/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f29b07c4-c0d0-4a42-b993-d524657bc50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_curr</th>\n",
       "      <th>MA_curr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28 19:20:00-05:00</th>\n",
       "      <td>25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 19:25:00-05:00</th>\n",
       "      <td>20</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 19:30:00-05:00</th>\n",
       "      <td>23</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 19:35:00-05:00</th>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 19:40:00-05:00</th>\n",
       "      <td>23</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Count_curr  MA_curr      time\n",
       "timestamp                                               \n",
       "2022-12-28 19:20:00-05:00          25     21.0  19:20:00\n",
       "2022-12-28 19:25:00-05:00          20     21.0  19:25:00\n",
       "2022-12-28 19:30:00-05:00          23     21.0  19:30:00\n",
       "2022-12-28 19:35:00-05:00          16     21.0  19:35:00\n",
       "2022-12-28 19:40:00-05:00          23     20.5  19:40:00"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746480b4-3b6a-469f-9ca0-6d118586bf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4694b-2706-4423-baff-21d0b33ea13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816697d8-5667-4f24-beca-a1014395f4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697277e0-b2bd-4eb9-8689-1a05b0c16715",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg.row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa0e2933-655f-4ce5-9c93-de069642500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on bytes object:\n",
      "\n",
      "class bytes(object)\n",
      " |  bytes(iterable_of_ints) -> bytes\n",
      " |  bytes(string, encoding[, errors]) -> bytes\n",
      " |  bytes(bytes_or_buffer) -> immutable copy of bytes_or_buffer\n",
      " |  bytes(int) -> bytes object of size given by the parameter initialized with null bytes\n",
      " |  bytes() -> empty bytes object\n",
      " |  \n",
      " |  Construct an immutable array of bytes from:\n",
      " |    - an iterable yielding integers in range(256)\n",
      " |    - a text string encoded using the specified encoding\n",
      " |    - any object implementing the buffer API.\n",
      " |    - an integer\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(...)\n",
      " |      B.capitalize() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with only its first character capitalized (ASCII)\n",
      " |      and the rest lower-cased.\n",
      " |  \n",
      " |  center(self, width, fillchar=b' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  count(...)\n",
      " |      B.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of subsection sub in\n",
      " |      bytes B[start:end].  Optional arguments start and end are interpreted\n",
      " |      as in slice notation.\n",
      " |  \n",
      " |  decode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Decode the bytes using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding with which to decode the bytes.\n",
      " |      errors\n",
      " |        The error handling scheme to use for the handling of decoding errors.\n",
      " |        The default is 'strict' meaning that decoding errors raise a\n",
      " |        UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n",
      " |        as well as any other name registered with codecs.register_error that\n",
      " |        can handle UnicodeDecodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      B.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if B ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      suffix can also be a tuple of bytes to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      B.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  hex(...)\n",
      " |      Create a str of hexadecimal numbers from a bytes object.\n",
      " |      \n",
      " |        sep\n",
      " |          An optional single character or byte to separate hex bytes.\n",
      " |        bytes_per_sep\n",
      " |          How many bytes between separators.  Positive values count from the\n",
      " |          right, negative values count from the left.\n",
      " |      \n",
      " |      Example:\n",
      " |      >>> value = b'\\xb9\\x01\\xef'\n",
      " |      >>> value.hex()\n",
      " |      'b901ef'\n",
      " |      >>> value.hex(':')\n",
      " |      'b9:01:ef'\n",
      " |      >>> value.hex(':', 2)\n",
      " |      'b9:01ef'\n",
      " |      >>> value.hex(':', -2)\n",
      " |      'b901:ef'\n",
      " |  \n",
      " |  index(...)\n",
      " |      B.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the subsection is not found.\n",
      " |  \n",
      " |  isalnum(...)\n",
      " |      B.isalnum() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are alphanumeric\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  isalpha(...)\n",
      " |      B.isalpha() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are alphabetic\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  isascii(...)\n",
      " |      B.isascii() -> bool\n",
      " |      \n",
      " |      Return True if B is empty or all characters in B are ASCII,\n",
      " |      False otherwise.\n",
      " |  \n",
      " |  isdigit(...)\n",
      " |      B.isdigit() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are digits\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  islower(...)\n",
      " |      B.islower() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in B are lowercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |  \n",
      " |  isspace(...)\n",
      " |      B.isspace() -> bool\n",
      " |      \n",
      " |      Return True if all characters in B are whitespace\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |  \n",
      " |  istitle(...)\n",
      " |      B.istitle() -> bool\n",
      " |      \n",
      " |      Return True if B is a titlecased string and there is at least one\n",
      " |      character in B, i.e. uppercase characters may only follow uncased\n",
      " |      characters and lowercase characters only cased ones. Return False\n",
      " |      otherwise.\n",
      " |  \n",
      " |  isupper(...)\n",
      " |      B.isupper() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in B are uppercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |  \n",
      " |  join(self, iterable_of_bytes, /)\n",
      " |      Concatenate any number of bytes objects.\n",
      " |      \n",
      " |      The bytes whose method is called is inserted in between each pair.\n",
      " |      \n",
      " |      The result is returned as a new bytes object.\n",
      " |      \n",
      " |      Example: b'.'.join([b'ab', b'pq', b'rs']) -> b'ab.pq.rs'.\n",
      " |  \n",
      " |  ljust(self, width, fillchar=b' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  lower(...)\n",
      " |      B.lower() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with all ASCII characters converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, bytes=None, /)\n",
      " |      Strip leading bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip leading  ASCII whitespace.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator sep in the bytes. If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original bytes\n",
      " |      object and two empty bytes objects.\n",
      " |  \n",
      " |  removeprefix(self, prefix, /)\n",
      " |      Return a bytes object with the given prefix string removed if present.\n",
      " |      \n",
      " |      If the bytes starts with the prefix string, return bytes[len(prefix):].\n",
      " |      Otherwise, return a copy of the original bytes.\n",
      " |  \n",
      " |  removesuffix(self, suffix, /)\n",
      " |      Return a bytes object with the given suffix string removed if present.\n",
      " |      \n",
      " |      If the bytes ends with the suffix string and that suffix is not empty,\n",
      " |      return bytes[:-len(prefix)].  Otherwise, return a copy of the original\n",
      " |      bytes.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      B.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      B.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raise ValueError when the subsection is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=b' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character.\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator sep in the bytes, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty bytes\n",
      " |      objects and the original bytes object.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the bytes.\n",
      " |          None (the default value) means split on ASCII whitespace characters\n",
      " |          (space, tab, return, newline, formfeed, vertical tab).\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splitting is done starting at the end of the bytes and working to the front.\n",
      " |  \n",
      " |  rstrip(self, bytes=None, /)\n",
      " |      Strip trailing bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip trailing ASCII whitespace.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the bytes.\n",
      " |        None (the default value) means split on ASCII whitespace characters\n",
      " |        (space, tab, return, newline, formfeed, vertical tab).\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the bytes, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      B.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if B starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      prefix can also be a tuple of bytes to try.\n",
      " |  \n",
      " |  strip(self, bytes=None, /)\n",
      " |      Strip leading and trailing bytes contained in the argument.\n",
      " |      \n",
      " |      If the argument is omitted or None, strip leading and trailing ASCII whitespace.\n",
      " |  \n",
      " |  swapcase(...)\n",
      " |      B.swapcase() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with uppercase ASCII characters converted\n",
      " |      to lowercase ASCII and vice versa.\n",
      " |  \n",
      " |  title(...)\n",
      " |      B.title() -> copy of B\n",
      " |      \n",
      " |      Return a titlecased version of B, i.e. ASCII words start with uppercase\n",
      " |      characters, all remaining cased characters have lowercase.\n",
      " |  \n",
      " |  translate(self, table, /, delete=b'')\n",
      " |      Return a copy with each character mapped by the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a bytes object of length 256.\n",
      " |      \n",
      " |      All characters occurring in the optional argument delete are removed.\n",
      " |      The remaining characters are mapped through the given translation table.\n",
      " |  \n",
      " |  upper(...)\n",
      " |      B.upper() -> copy of B\n",
      " |      \n",
      " |      Return a copy of B with all ASCII characters converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The original string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  fromhex(string, /) from builtins.type\n",
      " |      Create a bytes object from a string of hexadecimal numbers.\n",
      " |      \n",
      " |      Spaces between two numbers are accepted.\n",
      " |      Example: bytes.fromhex('B9 01EF') -> b'\\\\xb9\\\\x01\\\\xef'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(frm, to, /)\n",
      " |      Return a translation table useable for the bytes or bytearray translate method.\n",
      " |      \n",
      " |      The returned table will be one where each byte in frm is mapped to the byte at\n",
      " |      the same position in to.\n",
      " |      \n",
      " |      The bytes objects frm and to must be of the same length.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(msg.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ff40e0-bf75-434b-adf2-938aed5ebc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Message object:\n",
      "\n",
      "class Message(builtins.object)\n",
      " |  The Message object represents either a single consumed or produced message, or an event (:py:func:`error()` is not None).\n",
      " |  \n",
      " |  An application must check with :py:func:`error()` to see if the object is a proper message (error() returns None) or an error/event.\n",
      " |  \n",
      " |  This class is not user-instantiable.\n",
      " |  \n",
      " |  .. py:function:: len()\n",
      " |  \n",
      " |    :returns: Message value (payload) size in bytes\n",
      " |    :rtype: int\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  error(...)\n",
      " |      The message object is also used to propagate errors and events, an application must check error() to determine if the Message is a proper message (error() returns None) or an error or event (error() returns a KafkaError object)\n",
      " |      \n",
      " |      :rtype: None or :py:class:`KafkaError`\n",
      " |  \n",
      " |  headers(...)\n",
      " |      Retrieve the headers set on a message. Each header is a key valuepair. Please note that header keys are ordered and can repeat.\n",
      " |      \n",
      " |      :returns: list of two-tuples, one (key, value) pair for each header.\n",
      " |      :rtype: [(str, bytes),...] or None.\n",
      " |  \n",
      " |  key(...)\n",
      " |      :returns: message key or None if not available.\n",
      " |      :rtype: str|bytes or None\n",
      " |  \n",
      " |  latency(...)\n",
      " |      Retrieve the time it took to produce the message, from calling produce() to the time the acknowledgement was received from the broker.\n",
      " |      Must only be used with the producer for successfully produced messages.\n",
      " |      \n",
      " |        :returns: latency as float seconds, or None if latency information is not available (such as for errored messages).\n",
      " |        :rtype: float or None\n",
      " |  \n",
      " |  offset(...)\n",
      " |      :returns: message offset or None if not available.\n",
      " |      :rtype: int or None\n",
      " |  \n",
      " |  partition(...)\n",
      " |      :returns: partition number or None if not available.\n",
      " |      :rtype: int or None\n",
      " |  \n",
      " |  set_headers(...)\n",
      " |      Set the field 'Message.headers' with new value.\n",
      " |      \n",
      " |      :param object value: Message.headers.\n",
      " |      :returns: None.\n",
      " |      :rtype: None\n",
      " |  \n",
      " |  set_key(...)\n",
      " |      Set the field 'Message.key' with new value.\n",
      " |      \n",
      " |      :param object value: Message.key.\n",
      " |      :returns: None.\n",
      " |      :rtype: None\n",
      " |  \n",
      " |  set_value(...)\n",
      " |      Set the field 'Message.value' with new value.\n",
      " |      \n",
      " |      :param object value: Message.value.\n",
      " |      :returns: None.\n",
      " |      :rtype: None\n",
      " |  \n",
      " |  timestamp(...)\n",
      " |      Retrieve timestamp type and timestamp from message.\n",
      " |      The timestamp type is one of:\n",
      " |      \n",
      " |        * :py:const:`TIMESTAMP_NOT_AVAILABLE` - Timestamps not supported by broker.\n",
      " |        * :py:const:`TIMESTAMP_CREATE_TIME` - Message creation time (or source / producer time).\n",
      " |        * :py:const:`TIMESTAMP_LOG_APPEND_TIME` - Broker receive time.\n",
      " |      \n",
      " |        The returned timestamp should be ignored if the timestamp type is :py:const:`TIMESTAMP_NOT_AVAILABLE`.\n",
      " |      \n",
      " |        The timestamp is the number of milliseconds since the epoch (UTC).\n",
      " |      \n",
      " |        Timestamps require broker version 0.10.0.0 or later and ``{'api.version.request': True}`` configured on the client.\n",
      " |      \n",
      " |        :returns: tuple of message timestamp type, and timestamp.\n",
      " |        :rtype: (int, int)\n",
      " |  \n",
      " |  topic(...)\n",
      " |      :returns: topic name or None if not available.\n",
      " |      :rtype: str or None\n",
      " |  \n",
      " |  value(...)\n",
      " |      :returns: message value (payload) or None if not available.\n",
      " |      :rtype: str|bytes or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f960a-a46e-4f9a-a083-203d918a47dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278d3170-783a-4498-b630-7947bc9daa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cimpl.Message at 0x7f4d754475c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c773e146-2b2f-4b90-88ae-e91e87de6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = msg.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb05bbd0-cb86-45a0-b636-ba84480af5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"SUMFLAG\":1}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81066c94-4e9c-4b56-a961-175fceed2717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f23360-9211-49b4-89f8-6fde7ac741e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = json.loads(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470aee67-3b6c-4b3d-984a-4c8ebdae2611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SUMFLAG': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca657512-571a-4533-b0bf-9860900cbca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
